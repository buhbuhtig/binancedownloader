{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beedb082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶️  Запускаем тест: скачивание monthly архива для BTCUSDT (BINANCE-FUT) за 2023-10...\n",
      "Это может занять несколько минут...\n",
      "  ⏳ Обработано строк: 113.69 M\n",
      "\n",
      "✅  Успешно! Данные скачаны и обработаны.\n",
      "\n",
      "--- Итоговая информация ---\n",
      "Форма DataFrame (shape): 535,668 строк, 7 колонок\n",
      "\n",
      "--- Первые 5 строк (head) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>Ticks</th>\n",
       "      <th>Source</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-10-01 00:00:05</td>\n",
       "      <td>26951.0</td>\n",
       "      <td>26950.9</td>\n",
       "      <td>71931</td>\n",
       "      <td>41</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-10-01 00:00:10</td>\n",
       "      <td>26951.0</td>\n",
       "      <td>26946.4</td>\n",
       "      <td>754970</td>\n",
       "      <td>341</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-01 00:00:15</td>\n",
       "      <td>26946.5</td>\n",
       "      <td>26946.4</td>\n",
       "      <td>150765</td>\n",
       "      <td>49</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-01 00:00:20</td>\n",
       "      <td>26946.5</td>\n",
       "      <td>26946.4</td>\n",
       "      <td>97977</td>\n",
       "      <td>47</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-01 00:00:25</td>\n",
       "      <td>26946.5</td>\n",
       "      <td>26946.4</td>\n",
       "      <td>21045</td>\n",
       "      <td>27</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Timestamp        H        L       V  Ticks       Source   Ticker\n",
       "0 2023-10-01 00:00:05  26951.0  26950.9   71931     41  BINANCE-FUT  BTCUSDT\n",
       "1 2023-10-01 00:00:10  26951.0  26946.4  754970    341  BINANCE-FUT  BTCUSDT\n",
       "2 2023-10-01 00:00:15  26946.5  26946.4  150765     49  BINANCE-FUT  BTCUSDT\n",
       "3 2023-10-01 00:00:20  26946.5  26946.4   97977     47  BINANCE-FUT  BTCUSDT\n",
       "4 2023-10-01 00:00:25  26946.5  26946.4   21045     27  BINANCE-FUT  BTCUSDT"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Последние 5 строк (tail) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>H</th>\n",
       "      <th>L</th>\n",
       "      <th>V</th>\n",
       "      <th>Ticks</th>\n",
       "      <th>Source</th>\n",
       "      <th>Ticker</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>535663</th>\n",
       "      <td>2023-10-31 23:59:40</td>\n",
       "      <td>34662.6</td>\n",
       "      <td>34662.5</td>\n",
       "      <td>74767</td>\n",
       "      <td>34</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535664</th>\n",
       "      <td>2023-10-31 23:59:45</td>\n",
       "      <td>34662.6</td>\n",
       "      <td>34656.7</td>\n",
       "      <td>201926</td>\n",
       "      <td>216</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535665</th>\n",
       "      <td>2023-10-31 23:59:50</td>\n",
       "      <td>34660.7</td>\n",
       "      <td>34660.6</td>\n",
       "      <td>62319</td>\n",
       "      <td>39</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535666</th>\n",
       "      <td>2023-10-31 23:59:55</td>\n",
       "      <td>34660.7</td>\n",
       "      <td>34656.2</td>\n",
       "      <td>29459</td>\n",
       "      <td>104</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535667</th>\n",
       "      <td>2023-11-01 00:00:00</td>\n",
       "      <td>34656.3</td>\n",
       "      <td>34651.3</td>\n",
       "      <td>217684</td>\n",
       "      <td>197</td>\n",
       "      <td>BINANCE-FUT</td>\n",
       "      <td>BTCUSDT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Timestamp        H        L       V  Ticks       Source  \\\n",
       "535663 2023-10-31 23:59:40  34662.6  34662.5   74767     34  BINANCE-FUT   \n",
       "535664 2023-10-31 23:59:45  34662.6  34656.7  201926    216  BINANCE-FUT   \n",
       "535665 2023-10-31 23:59:50  34660.7  34660.6   62319     39  BINANCE-FUT   \n",
       "535666 2023-10-31 23:59:55  34660.7  34656.2   29459    104  BINANCE-FUT   \n",
       "535667 2023-11-01 00:00:00  34656.3  34651.3  217684    197  BINANCE-FUT   \n",
       "\n",
       "         Ticker  \n",
       "535663  BTCUSDT  \n",
       "535664  BTCUSDT  \n",
       "535665  BTCUSDT  \n",
       "535666  BTCUSDT  \n",
       "535667  BTCUSDT  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Проверка: общее количество тиков в месяце: 113,686,101\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "\n",
    "# Предполагается, что ваш ноутбук запущен из корня проекта\n",
    "from utils.downloader import download_and_process_ticks_to_df, SourceType, Frequency\n",
    "\n",
    "# --- Параметры для теста (используем месячный файл для наглядности) ---\n",
    "test_date = datetime.date(2023, 10, 1) # День не важен для monthly\n",
    "test_ticker = \"BTCUSDT\"\n",
    "test_source: SourceType = \"BINANCE-FUT\"\n",
    "test_frequency: Frequency = \"monthly\"\n",
    "\n",
    "print(f\"▶️  Запускаем тест: скачивание {test_frequency} архива для {test_ticker} ({test_source}) за {test_date.strftime('%Y-%m')}...\")\n",
    "print(\"Это может занять несколько минут...\")\n",
    "\n",
    "# --- 1. Определяем callback-функцию для отображения прогресса ---\n",
    "def report_progress(rows_count: int):\n",
    "    # Используем \\r и end='' для обновления строки на месте, создавая эффект \"живого\" счетчика\n",
    "    # Выводим в мега-строках (M) для лучшей читаемости\n",
    "    print(f\"  ⏳ Обработано строк: {rows_count / 1_000_000:.2f} M\", end='\\r')\n",
    "\n",
    "# --- 2. Вызов основной функции с callback ---\n",
    "data_df = None\n",
    "try:\n",
    "    data_df = download_and_process_ticks_to_df(\n",
    "        trade_date=test_date,\n",
    "        ticker=test_ticker,\n",
    "        source=test_source,\n",
    "        frequency=test_frequency,\n",
    "        progress_callback=report_progress # <-- Передаем нашу функцию\n",
    "    )\n",
    "    \n",
    "    # После завершения цикла выводим итоговое сообщение на новой строке\n",
    "    print(\"\\n\\n✅  Успешно! Данные скачаны и обработаны.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  Произошла ошибка при выполнении:\")\n",
    "    print(f\"Тип ошибки: {type(e).__name__}\")\n",
    "    print(f\"Детали: {e}\")\n",
    "\n",
    "# --- 3. Отображение статистики (если данные получены) ---\n",
    "if data_df is not None and not data_df.empty:\n",
    "    print(f\"\\n--- Итоговая информация ---\")\n",
    "    print(f\"Форма DataFrame (shape): {data_df.shape[0]:,} строк, {data_df.shape[1]} колонок\")\n",
    "    \n",
    "    print(\"\\n--- Первые 5 строк (head) ---\")\n",
    "    display(data_df.head())\n",
    "    \n",
    "    print(\"\\n--- Последние 5 строк (tail) ---\")\n",
    "    display(data_df.tail())\n",
    "\n",
    "    total_ticks = data_df['Ticks'].sum()\n",
    "    print(f\"\\nПроверка: общее количество тиков в месяце: {total_ticks:,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9644f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Модуль 'discovery' успешно импортирован.\n",
      "\n",
      "--- Получение DAILY файлов для BTCUSDT ---\n",
      "✅  Найдено 2148 дневных файлов.\n",
      "  Пример: 2019-09-08 -> 55,253 байт\n",
      "\n",
      "--- Получение MONTHLY файлов для BTCUSDT ---\n",
      "  ⏳ Найдено файлов: 70\n",
      "✅  Готово! Всего найдено 70 месячных файлов.\n",
      "\n",
      "--- Все найденные месячные файлы ---\n",
      "  Дата: 2019-09-01 (Месяц: 2019-09), Размер: 14,243,543 байт\n",
      "  Дата: 2019-10-01 (Месяц: 2019-10), Размер: 53,264,789 байт\n",
      "  Дата: 2019-11-01 (Месяц: 2019-11), Размер: 119,661,317 байт\n",
      "  Дата: 2019-12-01 (Месяц: 2019-12), Размер: 99,771,382 байт\n",
      "  Дата: 2020-01-01 (Месяц: 2020-01), Размер: 128,838,558 байт\n",
      "  Дата: 2020-02-01 (Месяц: 2020-02), Размер: 119,153,913 байт\n",
      "  Дата: 2020-03-01 (Месяц: 2020-03), Размер: 298,086,305 байт\n",
      "  Дата: 2020-04-01 (Месяц: 2020-04), Размер: 317,101,072 байт\n",
      "  Дата: 2020-05-01 (Месяц: 2020-05), Размер: 370,923,781 байт\n",
      "  Дата: 2020-06-01 (Месяц: 2020-06), Размер: 196,314,591 байт\n",
      "  Дата: 2020-07-01 (Месяц: 2020-07), Размер: 169,202,475 байт\n",
      "  Дата: 2020-08-01 (Месяц: 2020-08), Размер: 228,784,150 байт\n",
      "  Дата: 2020-09-01 (Месяц: 2020-09), Размер: 215,425,080 байт\n",
      "  Дата: 2020-10-01 (Месяц: 2020-10), Размер: 248,467,076 байт\n",
      "  Дата: 2020-11-01 (Месяц: 2020-11), Размер: 486,401,639 байт\n",
      "  Дата: 2020-12-01 (Месяц: 2020-12), Размер: 549,434,857 байт\n",
      "  Дата: 2021-01-01 (Месяц: 2021-01), Размер: 1,054,498,344 байт\n",
      "  Дата: 2021-02-01 (Месяц: 2021-02), Размер: 894,774,148 байт\n",
      "  Дата: 2021-03-01 (Месяц: 2021-03), Размер: 1,003,252,892 байт\n",
      "  Дата: 2021-04-01 (Месяц: 2021-04), Размер: 804,116,371 байт\n",
      "  Дата: 2021-05-01 (Месяц: 2021-05), Размер: 1,625,159,143 байт\n",
      "  Дата: 2021-06-01 (Месяц: 2021-06), Размер: 1,844,841,261 байт\n",
      "  Дата: 2021-07-01 (Месяц: 2021-07), Размер: 1,257,081,499 байт\n",
      "  Дата: 2021-08-01 (Месяц: 2021-08), Размер: 1,189,197,320 байт\n",
      "  Дата: 2021-09-01 (Месяц: 2021-09), Размер: 944,257,407 байт\n",
      "  Дата: 2021-10-01 (Месяц: 2021-10), Размер: 930,313,721 байт\n",
      "  Дата: 2021-11-01 (Месяц: 2021-11), Размер: 766,479,634 байт\n",
      "  Дата: 2021-12-01 (Месяц: 2021-12), Размер: 878,165,450 байт\n",
      "  Дата: 2022-01-01 (Месяц: 2022-01), Размер: 993,877,426 байт\n",
      "  Дата: 2022-02-01 (Месяц: 2022-02), Размер: 936,808,970 байт\n",
      "  Дата: 2022-03-01 (Месяц: 2022-03), Размер: 900,706,271 байт\n",
      "  Дата: 2022-04-01 (Месяц: 2022-04), Размер: 721,868,124 байт\n",
      "  Дата: 2022-05-01 (Месяц: 2022-05), Размер: 1,185,749,112 байт\n",
      "  Дата: 2022-06-01 (Месяц: 2022-06), Размер: 1,462,433,732 байт\n",
      "  Дата: 2022-07-01 (Месяц: 2022-07), Размер: 1,377,934,969 байт\n",
      "  Дата: 2022-08-01 (Месяц: 2022-08), Размер: 1,069,757,026 байт\n",
      "  Дата: 2022-09-01 (Месяц: 2022-09), Размер: 1,106,845,306 байт\n",
      "  Дата: 2022-10-01 (Месяц: 2022-10), Размер: 799,410,051 байт\n",
      "  Дата: 2022-11-01 (Месяц: 2022-11), Размер: 940,951,410 байт\n",
      "  Дата: 2022-12-01 (Месяц: 2022-12), Размер: 444,480,201 байт\n",
      "  Дата: 2023-01-01 (Месяц: 2023-01), Размер: 797,254,027 байт\n",
      "  Дата: 2023-02-01 (Месяц: 2023-02), Размер: 798,924,869 байт\n",
      "  Дата: 2023-03-01 (Месяц: 2023-03), Размер: 1,375,773,503 байт\n",
      "  Дата: 2023-04-01 (Месяц: 2023-04), Размер: 1,034,971,533 байт\n",
      "  Дата: 2023-05-01 (Месяц: 2023-05), Размер: 1,011,198,902 байт\n",
      "  Дата: 2023-06-01 (Месяц: 2023-06), Размер: 1,065,809,011 байт\n",
      "  Дата: 2023-07-01 (Месяц: 2023-07), Размер: 652,973,108 байт\n",
      "  Дата: 2023-08-01 (Месяц: 2023-08), Размер: 622,168,357 байт\n",
      "  Дата: 2023-09-01 (Месяц: 2023-09), Размер: 594,648,804 байт\n",
      "  Дата: 2023-10-01 (Месяц: 2023-10), Размер: 938,835,962 байт\n",
      "  Дата: 2023-11-01 (Месяц: 2023-11), Размер: 794,342,995 байт\n",
      "  Дата: 2023-12-01 (Месяц: 2023-12), Размер: 822,326,165 байт\n",
      "  Дата: 2024-01-01 (Месяц: 2024-01), Размер: 1,021,286,908 байт\n",
      "  Дата: 2024-02-01 (Месяц: 2024-02), Размер: 894,929,766 байт\n",
      "  Дата: 2024-03-01 (Месяц: 2024-03), Размер: 1,404,566,846 байт\n",
      "  Дата: 2024-04-01 (Месяц: 2024-04), Размер: 1,147,938,141 байт\n",
      "  Дата: 2024-05-01 (Месяц: 2024-05), Размер: 863,501,390 байт\n",
      "  Дата: 2024-06-01 (Месяц: 2024-06), Размер: 580,848,733 байт\n",
      "  Дата: 2024-07-01 (Месяц: 2024-07), Размер: 854,894,316 байт\n",
      "  Дата: 2024-08-01 (Месяц: 2024-08), Размер: 1,067,522,188 байт\n",
      "  Дата: 2024-09-01 (Месяц: 2024-09), Размер: 774,809,240 байт\n",
      "  Дата: 2024-10-01 (Месяц: 2024-10), Размер: 805,484,764 байт\n",
      "  Дата: 2024-11-01 (Месяц: 2024-11), Размер: 1,203,630,081 байт\n",
      "  Дата: 2024-12-01 (Месяц: 2024-12), Размер: 1,096,184,491 байт\n",
      "  Дата: 2025-01-01 (Месяц: 2025-01), Размер: 1,080,137,948 байт\n",
      "  Дата: 2025-02-01 (Месяц: 2025-02), Размер: 883,564,154 байт\n",
      "  Дата: 2025-03-01 (Месяц: 2025-03), Размер: 1,080,619,794 байт\n",
      "  Дата: 2025-04-01 (Месяц: 2025-04), Размер: 945,671,195 байт\n",
      "  Дата: 2025-05-01 (Месяц: 2025-05), Размер: 806,215,449 байт\n",
      "  Дата: 2025-06-01 (Месяц: 2025-06), Размер: 658,449,514 байт\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import date\n",
    "\n",
    "try:\n",
    "    # Импортируем обновленную функцию\n",
    "    from utils.discovery import get_ticker_files, SourceType, Frequency\n",
    "    print(\"✅  Модуль 'discovery' успешно импортирован.\")\n",
    "except ImportError:\n",
    "    print(\"❌  Ошибка импорта.\")\n",
    "    sys.exit()\n",
    "\n",
    "ticker_to_check = \"BTCUSDT\"\n",
    "source_to_check: SourceType = \"BINANCE-FUT\"\n",
    "\n",
    "# --- Тест 1: Получение ДНЕВНЫХ файлов (как раньше) ---\n",
    "print(f\"\\n--- Получение DAILY файлов для {ticker_to_check} ---\")\n",
    "try:\n",
    "    daily_files = get_ticker_files(\n",
    "        source=source_to_check,\n",
    "        ticker=ticker_to_check,\n",
    "        frequency=\"daily\"\n",
    "    )\n",
    "    print(f\"✅  Найдено {len(daily_files)} дневных файлов.\")\n",
    "    if daily_files:\n",
    "        first_day = sorted(daily_files.keys())[0]\n",
    "        print(f\"  Пример: {first_day} -> {daily_files[first_day]:,} байт\")\n",
    "except Exception as e:\n",
    "    print(f\"❌  Произошла ошибка: {e}\")\n",
    "\n",
    "\n",
    "# --- Тест 2: Получение МЕСЯЧНЫХ файлов ---\n",
    "print(f\"\\n--- Получение MONTHLY файлов для {ticker_to_check} ---\")\n",
    "try:\n",
    "    def report_progress(count: int):\n",
    "        print(f\"  ⏳ Найдено файлов: {count}\", end='\\r')\n",
    "\n",
    "    monthly_files = get_ticker_files(\n",
    "        source=source_to_check,\n",
    "        ticker=ticker_to_check,\n",
    "        frequency=\"monthly\",\n",
    "        progress_callback=report_progress\n",
    "    )\n",
    "    \n",
    "    print(f\"\\n✅  Готово! Всего найдено {len(monthly_files)} месячных файлов.\")\n",
    "    if monthly_files:\n",
    "        print(\"\\n--- Все найденные месячные файлы ---\")\n",
    "        for month_date, size in sorted(monthly_files.items()):\n",
    "            # Дата будет первым днем месяца\n",
    "            print(f\"  Дата: {month_date} (Месяц: {month_date.strftime('%Y-%m')}), Размер: {size:,} байт\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  Произошла ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "357db827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Модуль 'discovery' успешно импортирован.\n",
      "\n",
      "--- Получение списка дневных файлов для BTCUSDT (BINANCE-SPOT) ---\n",
      "  ⏳ Найдено файлов: 2900\n",
      "✅  Готово! Всего найдено 2900 дневных файлов.\n",
      "\n",
      "--- Первые 5 найденных файлов ---\n",
      "  Дата: 2017-08-17, Размер: 63,039 байт\n",
      "  Дата: 2017-08-18, Размер: 95,776 байт\n",
      "  Дата: 2017-08-19, Размер: 40,219 байт\n",
      "  Дата: 2017-08-20, Размер: 43,413 байт\n",
      "  Дата: 2017-08-21, Размер: 70,078 байт\n",
      "\n",
      "--- Последние 5 найденных файлов ---\n",
      "  Дата: 2025-07-21, Размер: 23,233,971 байт\n",
      "  Дата: 2025-07-22, Размер: 25,369,818 байт\n",
      "  Дата: 2025-07-23, Размер: 19,131,415 байт\n",
      "  Дата: 2025-07-24, Размер: 19,069,511 байт\n",
      "  Дата: 2025-07-25, Размер: 29,753,237 байт\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from datetime import date\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    # Импортируем обе функции из нашего модуля\n",
    "    from utils.discovery import get_available_tickers, get_ticker_daily_files, SourceType\n",
    "    print(\"✅  Модуль 'discovery' успешно импортирован.\")\n",
    "except ImportError:\n",
    "    print(\"❌  Ошибка импорта. Проверьте путь к utils.discovery.\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- Тест новой функции get_ticker_daily_files ---\n",
    "ticker_to_check = \"BTCUSDT\"\n",
    "source_to_check: SourceType = \"BINANCE-SPOT\"\n",
    "\n",
    "print(f\"\\n--- Получение списка дневных файлов для {ticker_to_check} ({source_to_check}) ---\")\n",
    "\n",
    "try:\n",
    "    # Определяем callback-функцию для прогресса\n",
    "    def report_progress(count: int):\n",
    "        print(f\"  ⏳ Найдено файлов: {count}\", end='\\r')\n",
    "\n",
    "    # Вызываем новую функцию\n",
    "    daily_files = get_ticker_daily_files(\n",
    "        source=source_to_check,\n",
    "        ticker=ticker_to_check,\n",
    "        progress_callback=report_progress\n",
    "    )\n",
    "\n",
    "    print(f\"\\n✅  Готово! Всего найдено {len(daily_files)} дневных файлов.\")\n",
    "\n",
    "    if daily_files:\n",
    "        # Сортируем даты для красивого вывода\n",
    "        sorted_dates = sorted(daily_files.keys())\n",
    "        \n",
    "        print(\"\\n--- Первые 5 найденных файлов ---\")\n",
    "        for d in sorted_dates[:5]:\n",
    "            print(f\"  Дата: {d}, Размер: {daily_files[d]:,} байт\")\n",
    "            \n",
    "        print(\"\\n--- Последние 5 найденных файлов ---\")\n",
    "        for d in sorted_dates[-5:]:\n",
    "            print(f\"  Дата: {d}, Размер: {daily_files[d]:,} байт\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  Произошла ошибка: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7b405a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Module 'discovery' successfully imported.\n",
      "\n",
      "--- Test 1: Discovering tickers for DAILY data (BINANCE-SPOT) ---\n",
      "  ⏳ Found daily tickers: 3205\n",
      "✅  Done! Found 3205 tickers with DAILY data.\n",
      "Sample: ['1000CATBNB', '1000CATFDUSD', '1000CATTRY', '1000CATUSDC', '1000CATUSDT']\n",
      "\n",
      "--- Test 2: Discovering tickers for MONTHLY data (BINANCE-SPOT) ---\n",
      "  ⏳ Found monthly tickers: 3182\n",
      "✅  Done! Found 3182 tickers with MONTHLY data.\n",
      "Sample: ['1000CATBNB', '1000CATFDUSD', '1000CATTRY', '1000CATUSDC', '1000CATUSDT']\n",
      "\n",
      "--- Test 3: Comparing DAILY vs MONTHLY ticker sets ---\n",
      "\n",
      "⚠️  The sets of tickers are DIFFERENT.\n",
      "\n",
      "  - Found 23 tickers that ONLY have DAILY data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"Sample: ['AXSUSDC', 'CBNB', 'CFDUSD', 'COMPUSDC', 'CTRY']\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    # Import the updated function and types\n",
    "    from utils.discovery import get_available_tickers, SourceType, Frequency\n",
    "    print(\"✅  Module 'discovery' successfully imported.\")\n",
    "except ImportError:\n",
    "    print(\"❌  Import Error. Please check the path to utils.discovery.\")\n",
    "    sys.exit()\n",
    "\n",
    "source_to_check: SourceType = \"BINANCE-SPOT\"\n",
    "\n",
    "# --- Test 1: Get tickers for DAILY frequency ---\n",
    "print(f\"\\n--- Test 1: Discovering tickers for DAILY data ({source_to_check}) ---\")\n",
    "try:\n",
    "    def report_daily_progress(count: int):\n",
    "        print(f\"  ⏳ Found daily tickers: {count}\", end='\\r')\n",
    "\n",
    "    daily_tickers = get_available_tickers(\n",
    "        source=source_to_check,\n",
    "        frequency=\"daily\",\n",
    "        ticker_filter=None, # Get all tickers to compare fairly\n",
    "        progress_callback=report_daily_progress\n",
    "    )\n",
    "    print(f\"\\n✅  Done! Found {len(daily_tickers)} tickers with DAILY data.\")\n",
    "    print(\"Sample:\", sorted(list(daily_tickers))[:5])\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  An error occurred: {e}\")\n",
    "    daily_tickers = set() # Initialize as empty set on error to allow comparison later\n",
    "\n",
    "\n",
    "# --- Test 2: Get tickers for MONTHLY frequency ---\n",
    "print(f\"\\n--- Test 2: Discovering tickers for MONTHLY data ({source_to_check}) ---\")\n",
    "try:\n",
    "    def report_monthly_progress(count: int):\n",
    "        print(f\"  ⏳ Found monthly tickers: {count}\", end='\\r')\n",
    "\n",
    "    monthly_tickers = get_available_tickers(\n",
    "        source=source_to_check,\n",
    "        frequency=\"monthly\",\n",
    "        ticker_filter=None, # Get all tickers\n",
    "        progress_callback=report_monthly_progress\n",
    "    )\n",
    "    print(f\"\\n✅  Done! Found {len(monthly_tickers)} tickers with MONTHLY data.\")\n",
    "    print(\"Sample:\", sorted(list(monthly_tickers))[:5])\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  An error occurred: {e}\")\n",
    "    monthly_tickers = set()\n",
    "\n",
    "\n",
    "# --- Test 3: Compare the two sets of tickers ---\n",
    "print(\"\\n--- Test 3: Comparing DAILY vs MONTHLY ticker sets ---\")\n",
    "\n",
    "if daily_tickers and monthly_tickers:\n",
    "    # Check if the sets are identical\n",
    "    if daily_tickers == monthly_tickers:\n",
    "        print(\"\\n✅  The set of tickers for daily and monthly data is IDENTICAL.\")\n",
    "    else:\n",
    "        print(\"\\n⚠️  The sets of tickers are DIFFERENT.\")\n",
    "\n",
    "        # Find tickers that only have daily data\n",
    "        only_daily = daily_tickers - monthly_tickers\n",
    "        if only_daily:\n",
    "            print(f\"\\n  - Found {len(only_daily)} tickers that ONLY have DAILY data.\")\n",
    "            display(f\"Sample: {sorted(list(only_daily))[:5]}\")\n",
    "\n",
    "        # Find tickers that only have monthly data\n",
    "        only_monthly = monthly_tickers - daily_tickers\n",
    "        if only_monthly:\n",
    "            print(f\"\\n  - Found {len(only_monthly)} tickers that ONLY have MONTHLY data.\")\n",
    "            display(f\"Sample: {sorted(list(only_monthly))[:5]}\")\n",
    "else:\n",
    "    print(\"\\nCould not perform comparison due to an error in one of the previous steps.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49a361b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Декоратор 'retry_on_io_error' успешно импортирован.\n",
      "\n",
      "--- Тест 1: Функция, которая срабатывает на 3-й попытке ---\n",
      "Вызов mock_flaky_function, попытка №1...\n",
      "Warning: Function 'mock_flaky_function' failed with ConnectionError: Симуляция обрыва сети. Retrying in 2s... (Attempt 1/4)\n",
      "Вызов mock_flaky_function, попытка №2...\n",
      "Warning: Function 'mock_flaky_function' failed with ConnectionError: Симуляция обрыва сети. Retrying in 2s... (Attempt 2/4)\n",
      "Вызов mock_flaky_function, попытка №3...\n",
      "\n",
      "✅  Итоговый результат: Успех на попытке №3!\n",
      "\n",
      "\n",
      "--- Тест 2: Функция, которая падает всегда ---\n",
      "Вызов mock_always_failing_function, попытка №1...\n",
      "Warning: Function 'mock_always_failing_function' failed with Timeout: Сервер не отвечает (симуляция). Retrying in 1s... (Attempt 1/3)\n",
      "Вызов mock_always_failing_function, попытка №2...\n",
      "Warning: Function 'mock_always_failing_function' failed with Timeout: Сервер не отвечает (симуляция). Retrying in 1s... (Attempt 2/3)\n",
      "Вызов mock_always_failing_function, попытка №3...\n",
      "Error: All 3 retries for 'mock_always_failing_function' failed.\n",
      "\n",
      "✅  Успешно перехвачена последняя ошибка, как и ожидалось:\n",
      "   Тип: Timeout, Сообщение: Сервер не отвечает (симуляция)\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import requests\n",
    "from IPython.display import display\n",
    "\n",
    "try:\n",
    "    # Импортируем наш новый декоратор\n",
    "    from utils.decorators import retry_on_io_error\n",
    "    print(\"✅  Декоратор 'retry_on_io_error' успешно импортирован.\")\n",
    "except ImportError:\n",
    "    print(\"❌  Ошибка импорта. Убедитесь, что существует файл utils/decorators.py.\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- Тест 1: Демонстрация успешного повтора ---\n",
    "print(\"\\n--- Тест 1: Функция, которая срабатывает на 3-й попытке ---\")\n",
    "\n",
    "# Используем nonlocal для изменения переменной из внешней области видимости\n",
    "call_count_success = 0\n",
    "@retry_on_io_error(retries=4, delay=2)\n",
    "def mock_flaky_function():\n",
    "    \"\"\"Эта функция падает 2 раза, а на 3-й срабатывает.\"\"\"\n",
    "    global call_count_success\n",
    "    call_count_success += 1\n",
    "    print(f\"Вызов mock_flaky_function, попытка №{call_count_success}...\")\n",
    "    if call_count_success < 3:\n",
    "        raise requests.exceptions.ConnectionError(\"Симуляция обрыва сети\")\n",
    "    return f\"Успех на попытке №{call_count_success}!\"\n",
    "\n",
    "try:\n",
    "    result = mock_flaky_function()\n",
    "    print(f\"\\n✅  Итоговый результат: {result}\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n❌  Неожиданная ошибка: {e}\")\n",
    "\n",
    "\n",
    "# --- Тест 2: Демонстрация полного провала и re-raise ---\n",
    "print(\"\\n\\n--- Тест 2: Функция, которая падает всегда ---\")\n",
    "\n",
    "call_count_fail = 0\n",
    "@retry_on_io_error(retries=3, delay=1)\n",
    "def mock_always_failing_function():\n",
    "    \"\"\"Эта функция падает всегда.\"\"\"\n",
    "    global call_count_fail\n",
    "    call_count_fail += 1\n",
    "    print(f\"Вызов mock_always_failing_function, попытка №{call_count_fail}...\")\n",
    "    raise requests.exceptions.Timeout(\"Сервер не отвечает (симуляция)\")\n",
    "\n",
    "try:\n",
    "    mock_always_failing_function()\n",
    "except requests.exceptions.Timeout as e:\n",
    "    print(f\"\\n✅  Успешно перехвачена последняя ошибка, как и ожидалось:\")\n",
    "    print(f\"   Тип: {type(e).__name__}, Сообщение: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a7772ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 03:18:16 - INFO - Подключаемся к ClickHouse по адресу: 172.16.0.9...\n",
      "2025-07-27 03:18:16 - WARNING - --- 1. ОЧИСТКА ПЕРЕД ТЕСТОМ ---\n",
      "2025-07-27 03:18:16 - WARNING - Удаляем все предыдущие записи для BTCUSDT (BINANCE-FUT)...\n",
      "2025-07-27 03:18:16 - INFO - Таблица 'hl5s_test' очищена.\n",
      "2025-07-27 03:18:16 - INFO - Таблица 'hl5s_daily_downloaded' очищена.\n",
      "2025-07-27 03:18:16 - WARNING - --- Очистка завершена. Начинаем тест. ---\n",
      "2025-07-27 03:18:16 - INFO - \n",
      "--- 2. ЗАПУСК _monthly_bulk_load для BTCUSDT ---\n",
      "2025-07-27 03:18:16 - INFO - Этот процесс может занять значительное время...\n",
      "2025-07-27 03:18:16 - INFO - [BTCUSDT] Начальная загрузка: ищем месячные архивы...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Модули успешно импортированы.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 03:18:18 - INFO - [BTCUSDT] Найдено 70 месячных архивов. Начинаем обработку...\n",
      "2025-07-27 03:18:18 - INFO - [BTCUSDT] Обрабатываем месяц 2019-09 (размер: 14.24 MB)...\n",
      "2025-07-27 03:18:18 - INFO - [BTCUSDT] Скачивание основного файла за 2019-09...\n",
      "2025-07-27 03:18:21 - INFO - [BTCUSDT] Основной файл за 2019-09 успешно скачан (14.24 MB).\n",
      "2025-07-27 03:18:21 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2019-09...\n",
      "2025-07-27 03:18:22 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:18:22 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2019-09...\n",
      "2025-07-27 03:18:22 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:18:22 - INFO - [BTCUSDT] Начало обработки данных из файла за 2019-09...\n",
      "2025-07-27 03:18:23 - INFO - [BTCUSDT] Данные из файла за 2019-09 успешно обработаны.\n",
      "2025-07-27 03:18:23 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2019-09-08 17:57:55 по 2019-10-01 00:00:00\n",
      "2025-07-27 03:18:23 - INFO - [BTCUSDT] Вставляем 306414 баров в 'hl5s_test'...\n",
      "2025-07-27 03:18:24 - INFO - [BTCUSDT] Вставляем 23 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:18:24 - INFO - [BTCUSDT] Месяц 2019-09 успешно загружен.\n",
      "2025-07-27 03:18:24 - INFO - [BTCUSDT] Обрабатываем месяц 2019-10 (размер: 53.26 MB)...\n",
      "2025-07-27 03:18:24 - INFO - [BTCUSDT] Скачивание основного файла за 2019-10...\n",
      "2025-07-27 03:18:30 - INFO - [BTCUSDT] Основной файл за 2019-10 успешно скачан (53.26 MB).\n",
      "2025-07-27 03:18:30 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2019-10...\n",
      "2025-07-27 03:18:31 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:18:31 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2019-10...\n",
      "2025-07-27 03:18:31 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:18:31 - INFO - [BTCUSDT] Начало обработки данных из файла за 2019-10...\n",
      "2025-07-27 03:18:38 - INFO - [BTCUSDT] Данные из файла за 2019-10 успешно обработаны.\n",
      "2025-07-27 03:18:38 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2019-10-01 00:00:05 по 2019-11-01 00:00:00\n",
      "2025-07-27 03:18:38 - INFO - [BTCUSDT] Вставляем 494018 баров в 'hl5s_test'...\n",
      "2025-07-27 03:18:39 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:18:39 - INFO - [BTCUSDT] Месяц 2019-10 успешно загружен.\n",
      "2025-07-27 03:18:39 - INFO - [BTCUSDT] Обрабатываем месяц 2019-11 (размер: 119.66 MB)...\n",
      "2025-07-27 03:18:39 - INFO - [BTCUSDT] Скачивание основного файла за 2019-11...\n",
      "2025-07-27 03:18:49 - INFO - [BTCUSDT] Основной файл за 2019-11 успешно скачан (119.66 MB).\n",
      "2025-07-27 03:18:49 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2019-11...\n",
      "2025-07-27 03:18:50 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:18:50 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2019-11...\n",
      "2025-07-27 03:18:50 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:18:50 - INFO - [BTCUSDT] Начало обработки данных из файла за 2019-11...\n",
      "2025-07-27 03:19:07 - INFO - [BTCUSDT] Данные из файла за 2019-11 успешно обработаны.\n",
      "2025-07-27 03:19:07 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2019-11-01 00:00:05 по 2019-12-01 00:00:00\n",
      "2025-07-27 03:19:07 - INFO - [BTCUSDT] Вставляем 471378 баров в 'hl5s_test'...\n",
      "2025-07-27 03:19:08 - INFO - [BTCUSDT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:19:08 - INFO - [BTCUSDT] Месяц 2019-11 успешно загружен.\n",
      "2025-07-27 03:19:08 - INFO - [BTCUSDT] Обрабатываем месяц 2019-12 (размер: 99.77 MB)...\n",
      "2025-07-27 03:19:08 - INFO - [BTCUSDT] Скачивание основного файла за 2019-12...\n",
      "2025-07-27 03:19:17 - INFO - [BTCUSDT] Основной файл за 2019-12 успешно скачан (99.77 MB).\n",
      "2025-07-27 03:19:17 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2019-12...\n",
      "2025-07-27 03:19:17 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:19:17 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2019-12...\n",
      "2025-07-27 03:19:18 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:19:18 - INFO - [BTCUSDT] Начало обработки данных из файла за 2019-12...\n",
      "2025-07-27 03:19:30 - INFO - [BTCUSDT] Данные из файла за 2019-12 успешно обработаны.\n",
      "2025-07-27 03:19:30 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2019-12-01 00:00:05 по 2019-12-31 23:59:55\n",
      "2025-07-27 03:19:30 - INFO - [BTCUSDT] Вставляем 480338 баров в 'hl5s_test'...\n",
      "2025-07-27 03:19:31 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:19:31 - INFO - [BTCUSDT] Месяц 2019-12 успешно загружен.\n",
      "2025-07-27 03:19:31 - INFO - [BTCUSDT] Обрабатываем месяц 2020-01 (размер: 128.84 MB)...\n",
      "2025-07-27 03:19:31 - INFO - [BTCUSDT] Скачивание основного файла за 2020-01...\n",
      "2025-07-27 03:19:41 - INFO - [BTCUSDT] Основной файл за 2020-01 успешно скачан (128.84 MB).\n",
      "2025-07-27 03:19:41 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-01...\n",
      "2025-07-27 03:19:42 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:19:42 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-01...\n",
      "2025-07-27 03:19:42 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:19:42 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-01...\n",
      "2025-07-27 03:19:59 - INFO - [BTCUSDT] Данные из файла за 2020-01 успешно обработаны.\n",
      "2025-07-27 03:19:59 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-01-01 00:00:05 по 2020-02-01 00:00:00\n",
      "2025-07-27 03:19:59 - INFO - [BTCUSDT] Вставляем 489832 баров в 'hl5s_test'...\n",
      "2025-07-27 03:20:00 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:20:00 - INFO - [BTCUSDT] Месяц 2020-01 успешно загружен.\n",
      "2025-07-27 03:20:00 - INFO - [BTCUSDT] Обрабатываем месяц 2020-02 (размер: 119.15 MB)...\n",
      "2025-07-27 03:20:00 - INFO - [BTCUSDT] Скачивание основного файла за 2020-02...\n",
      "2025-07-27 03:20:09 - INFO - [BTCUSDT] Основной файл за 2020-02 успешно скачан (119.15 MB).\n",
      "2025-07-27 03:20:09 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-02...\n",
      "2025-07-27 03:20:10 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:20:10 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-02...\n",
      "2025-07-27 03:20:10 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:20:10 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-02...\n",
      "2025-07-27 03:20:25 - INFO - [BTCUSDT] Данные из файла за 2020-02 успешно обработаны.\n",
      "2025-07-27 03:20:25 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-02-01 00:00:05 по 2020-03-01 00:00:00\n",
      "2025-07-27 03:20:25 - INFO - [BTCUSDT] Вставляем 469261 баров в 'hl5s_test'...\n",
      "2025-07-27 03:20:26 - INFO - [BTCUSDT] Вставляем 29 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:20:26 - INFO - [BTCUSDT] Месяц 2020-02 успешно загружен.\n",
      "2025-07-27 03:20:26 - INFO - [BTCUSDT] Обрабатываем месяц 2020-03 (размер: 298.09 MB)...\n",
      "2025-07-27 03:20:26 - INFO - [BTCUSDT] Скачивание основного файла за 2020-03...\n",
      "2025-07-27 03:20:46 - INFO - [BTCUSDT] Основной файл за 2020-03 успешно скачан (298.09 MB).\n",
      "2025-07-27 03:20:46 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-03...\n",
      "2025-07-27 03:20:47 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:20:47 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-03...\n",
      "2025-07-27 03:20:48 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:20:48 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-03...\n",
      "2025-07-27 03:21:26 - INFO - [BTCUSDT] Данные из файла за 2020-03 успешно обработаны.\n",
      "2025-07-27 03:21:27 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-03-01 00:00:05 по 2020-04-01 00:00:00\n",
      "2025-07-27 03:21:27 - INFO - [BTCUSDT] Вставляем 526200 баров в 'hl5s_test'...\n",
      "2025-07-27 03:21:28 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:21:28 - INFO - [BTCUSDT] Месяц 2020-03 успешно загружен.\n",
      "2025-07-27 03:21:28 - INFO - [BTCUSDT] Обрабатываем месяц 2020-04 (размер: 317.10 MB)...\n",
      "2025-07-27 03:21:28 - INFO - [BTCUSDT] Скачивание основного файла за 2020-04...\n",
      "2025-07-27 03:22:01 - INFO - [BTCUSDT] Основной файл за 2020-04 успешно скачан (317.10 MB).\n",
      "2025-07-27 03:22:01 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-04...\n",
      "2025-07-27 03:22:02 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:22:02 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-04...\n",
      "2025-07-27 03:22:03 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:22:03 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-04...\n",
      "2025-07-27 03:22:49 - INFO - [BTCUSDT] Данные из файла за 2020-04 успешно обработаны.\n",
      "2025-07-27 03:22:49 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-04-01 00:00:05 по 2020-05-01 00:00:00\n",
      "2025-07-27 03:22:49 - INFO - [BTCUSDT] Вставляем 515323 баров в 'hl5s_test'...\n",
      "2025-07-27 03:22:51 - INFO - [BTCUSDT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:22:51 - INFO - [BTCUSDT] Месяц 2020-04 успешно загружен.\n",
      "2025-07-27 03:22:51 - INFO - [BTCUSDT] Обрабатываем месяц 2020-05 (размер: 370.92 MB)...\n",
      "2025-07-27 03:22:51 - INFO - [BTCUSDT] Скачивание основного файла за 2020-05...\n",
      "2025-07-27 03:23:16 - INFO - [BTCUSDT] Основной файл за 2020-05 успешно скачан (370.92 MB).\n",
      "2025-07-27 03:23:16 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-05...\n",
      "2025-07-27 03:23:16 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:23:16 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-05...\n",
      "2025-07-27 03:23:18 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:23:18 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-05...\n",
      "2025-07-27 03:24:10 - INFO - [BTCUSDT] Данные из файла за 2020-05 успешно обработаны.\n",
      "2025-07-27 03:24:10 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-05-01 00:00:10 по 2020-06-01 00:00:00\n",
      "2025-07-27 03:24:10 - INFO - [BTCUSDT] Вставляем 535233 баров в 'hl5s_test'...\n",
      "2025-07-27 03:24:11 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:24:11 - INFO - [BTCUSDT] Месяц 2020-05 успешно загружен.\n",
      "2025-07-27 03:24:11 - INFO - [BTCUSDT] Обрабатываем месяц 2020-06 (размер: 196.31 MB)...\n",
      "2025-07-27 03:24:12 - INFO - [BTCUSDT] Скачивание основного файла за 2020-06...\n",
      "2025-07-27 03:24:38 - INFO - [BTCUSDT] Основной файл за 2020-06 успешно скачан (196.31 MB).\n",
      "2025-07-27 03:24:38 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-06...\n",
      "2025-07-27 03:24:39 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:24:39 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-06...\n",
      "2025-07-27 03:24:40 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:24:40 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-06...\n",
      "2025-07-27 03:25:07 - INFO - [BTCUSDT] Данные из файла за 2020-06 успешно обработаны.\n",
      "2025-07-27 03:25:07 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-06-01 00:00:05 по 2020-07-01 00:00:00\n",
      "2025-07-27 03:25:07 - INFO - [BTCUSDT] Вставляем 513912 баров в 'hl5s_test'...\n",
      "2025-07-27 03:25:08 - INFO - [BTCUSDT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:25:08 - INFO - [BTCUSDT] Месяц 2020-06 успешно загружен.\n",
      "2025-07-27 03:25:08 - INFO - [BTCUSDT] Обрабатываем месяц 2020-07 (размер: 169.20 MB)...\n",
      "2025-07-27 03:25:08 - INFO - [BTCUSDT] Скачивание основного файла за 2020-07...\n",
      "2025-07-27 03:25:21 - INFO - [BTCUSDT] Основной файл за 2020-07 успешно скачан (169.20 MB).\n",
      "2025-07-27 03:25:21 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-07...\n",
      "2025-07-27 03:25:22 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:25:22 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-07...\n",
      "2025-07-27 03:25:23 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:25:23 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-07...\n",
      "2025-07-27 03:25:48 - INFO - [BTCUSDT] Данные из файла за 2020-07 успешно обработаны.\n",
      "2025-07-27 03:25:48 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-07-01 00:00:05 по 2020-08-01 00:00:00\n",
      "2025-07-27 03:25:48 - INFO - [BTCUSDT] Вставляем 520820 баров в 'hl5s_test'...\n",
      "2025-07-27 03:25:49 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:25:49 - INFO - [BTCUSDT] Месяц 2020-07 успешно загружен.\n",
      "2025-07-27 03:25:49 - INFO - [BTCUSDT] Обрабатываем месяц 2020-08 (размер: 228.78 MB)...\n",
      "2025-07-27 03:25:49 - INFO - [BTCUSDT] Скачивание основного файла за 2020-08...\n",
      "2025-07-27 03:26:06 - INFO - [BTCUSDT] Основной файл за 2020-08 успешно скачан (228.78 MB).\n",
      "2025-07-27 03:26:06 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-08...\n",
      "2025-07-27 03:26:07 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:26:07 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-08...\n",
      "2025-07-27 03:26:07 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:26:07 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-08...\n",
      "2025-07-27 03:26:42 - INFO - [BTCUSDT] Данные из файла за 2020-08 успешно обработаны.\n",
      "2025-07-27 03:26:42 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-08-01 00:00:05 по 2020-09-01 00:00:00\n",
      "2025-07-27 03:26:42 - INFO - [BTCUSDT] Вставляем 532124 баров в 'hl5s_test'...\n",
      "2025-07-27 03:26:43 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:26:43 - INFO - [BTCUSDT] Месяц 2020-08 успешно загружен.\n",
      "2025-07-27 03:26:43 - INFO - [BTCUSDT] Обрабатываем месяц 2020-09 (размер: 215.43 MB)...\n",
      "2025-07-27 03:26:43 - INFO - [BTCUSDT] Скачивание основного файла за 2020-09...\n",
      "2025-07-27 03:26:59 - INFO - [BTCUSDT] Основной файл за 2020-09 успешно скачан (215.43 MB).\n",
      "2025-07-27 03:26:59 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-09...\n",
      "2025-07-27 03:26:59 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:26:59 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-09...\n",
      "2025-07-27 03:27:00 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:27:00 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-09...\n",
      "2025-07-27 03:27:35 - INFO - [BTCUSDT] Данные из файла за 2020-09 успешно обработаны.\n",
      "2025-07-27 03:27:35 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-09-01 00:00:05 по 2020-10-01 00:00:00\n",
      "2025-07-27 03:27:35 - INFO - [BTCUSDT] Вставляем 514709 баров в 'hl5s_test'...\n",
      "2025-07-27 03:27:36 - INFO - [BTCUSDT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:27:36 - INFO - [BTCUSDT] Месяц 2020-09 успешно загружен.\n",
      "2025-07-27 03:27:36 - INFO - [BTCUSDT] Обрабатываем месяц 2020-10 (размер: 248.47 MB)...\n",
      "2025-07-27 03:27:36 - INFO - [BTCUSDT] Скачивание основного файла за 2020-10...\n",
      "2025-07-27 03:28:06 - INFO - [BTCUSDT] Основной файл за 2020-10 успешно скачан (248.47 MB).\n",
      "2025-07-27 03:28:06 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-10...\n",
      "2025-07-27 03:28:07 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:28:07 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-10...\n",
      "2025-07-27 03:28:08 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:28:08 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-10...\n",
      "2025-07-27 03:28:46 - INFO - [BTCUSDT] Данные из файла за 2020-10 успешно обработаны.\n",
      "2025-07-27 03:28:46 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-10-01 00:00:05 по 2020-11-01 00:00:00\n",
      "2025-07-27 03:28:46 - INFO - [BTCUSDT] Вставляем 531607 баров в 'hl5s_test'...\n",
      "2025-07-27 03:28:47 - INFO - [BTCUSDT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:28:47 - INFO - [BTCUSDT] Месяц 2020-10 успешно загружен.\n",
      "2025-07-27 03:28:47 - INFO - [BTCUSDT] Обрабатываем месяц 2020-11 (размер: 486.40 MB)...\n",
      "2025-07-27 03:28:47 - INFO - [BTCUSDT] Скачивание основного файла за 2020-11...\n",
      "2025-07-27 03:29:20 - INFO - [BTCUSDT] Основной файл за 2020-11 успешно скачан (486.40 MB).\n",
      "2025-07-27 03:29:20 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-11...\n",
      "2025-07-27 03:29:20 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:29:20 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-11...\n",
      "2025-07-27 03:29:22 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:29:22 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-11...\n",
      "2025-07-27 03:30:35 - INFO - [BTCUSDT] Данные из файла за 2020-11 успешно обработаны.\n",
      "2025-07-27 03:30:35 - INFO - [BTCUSDT] Диапазон времени для вставки: с 2020-11-01 00:00:05 по 2020-12-01 00:00:00\n",
      "2025-07-27 03:30:35 - INFO - [BTCUSDT] Вставляем 518222 баров в 'hl5s_test'...\n",
      "2025-07-27 03:30:37 - INFO - [BTCUSDT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 03:30:37 - INFO - [BTCUSDT] Месяц 2020-11 успешно загружен.\n",
      "2025-07-27 03:30:37 - INFO - [BTCUSDT] Обрабатываем месяц 2020-12 (размер: 549.43 MB)...\n",
      "2025-07-27 03:30:37 - INFO - [BTCUSDT] Скачивание основного файла за 2020-12...\n",
      "2025-07-27 03:31:12 - INFO - [BTCUSDT] Основной файл за 2020-12 успешно скачан (549.43 MB).\n",
      "2025-07-27 03:31:12 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2020-12...\n",
      "2025-07-27 03:31:12 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 03:31:12 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2020-12...\n",
      "2025-07-27 03:31:14 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 03:31:14 - INFO - [BTCUSDT] Начало обработки данных из файла за 2020-12...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 72\u001b[0m\n\u001b[1;32m     69\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mЭтот процесс может занять значительное время...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     71\u001b[0m     \u001b[38;5;66;03m# Вызываем функцию, которую тестируем\u001b[39;00m\n\u001b[0;32m---> 72\u001b[0m     \u001b[43m_monthly_bulk_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSOURCE_TO_TEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     74\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTICKER_TO_TEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\n\u001b[1;32m     76\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Тест _monthly_bulk_load для \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTICKER_TO_TEST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m УСПЕШНО ЗАВЕРШЕН ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     80\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py:56\u001b[0m, in \u001b[0;36m_monthly_bulk_load\u001b[0;34m(source, ticker, client)\u001b[0m\n\u001b[1;32m     54\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Обрабатываем месяц \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m (размер: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1e6\u001b[39m\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m MB)...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 56\u001b[0m     full_df \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_process_ticks_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmonth_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonthly\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m     58\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] DataFrame для месяца \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth_date\u001b[38;5;241m.\u001b[39mstrftime(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mY-\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mm\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m пуст.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/decorators.py:42\u001b[0m, in \u001b[0;36mretry_on_io_error.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# Попытка выполнить функцию\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IO_EXCEPTIONS \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     44\u001b[0m         last_exception \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py:120\u001b[0m, in \u001b[0;36mdownload_and_process_ticks_to_df\u001b[0;34m(trade_date, ticker, source, frequency, chunksize, progress_callback)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     chunk_iterator \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m    117\u001b[0m         csv_stream, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mfull_col_names,\n\u001b[1;32m    118\u001b[0m         usecols\u001b[38;5;241m=\u001b[39mCOLS_TO_USE, dtype\u001b[38;5;241m=\u001b[39mDTYPES, chunksize\u001b[38;5;241m=\u001b[39mchunksize\n\u001b[1;32m    119\u001b[0m     )\n\u001b[0;32m--> 120\u001b[0m     processed_chunks \u001b[38;5;241m=\u001b[39m \u001b[43m_process_chunk_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert string to float\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py:48\u001b[0m, in \u001b[0;36m_process_chunk_iterator\u001b[0;34m(chunk_iterator, progress_callback)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m progress_callback:\n\u001b[1;32m     46\u001b[0m     progress_callback(total_rows_processed)\n\u001b[0;32m---> 48\u001b[0m chunk_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_df\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp_ms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43munit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mms\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m chunk_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m chunk_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m*\u001b[39m chunk_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mqty\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m     51\u001b[0m agg_chunk \u001b[38;5;241m=\u001b[39m chunk_df\u001b[38;5;241m.\u001b[39mresample(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m5s\u001b[39m\u001b[38;5;124m'\u001b[39m, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m, closed\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mright\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\n\u001b[1;32m     52\u001b[0m     H\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     53\u001b[0m     L\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmin\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     54\u001b[0m     V\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msum\u001b[39m\u001b[38;5;124m'\u001b[39m),\n\u001b[1;32m     55\u001b[0m     Ticks\u001b[38;5;241m=\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprice\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     56\u001b[0m )\u001b[38;5;241m.\u001b[39mdropna()\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:1063\u001b[0m, in \u001b[0;36mto_datetime\u001b[0;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[1;32m   1061\u001b[0m             result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutc\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, ABCSeries):\n\u001b[0;32m-> 1063\u001b[0m     cache_array \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconvert_listlike\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1064\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m cache_array\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m   1065\u001b[0m         result \u001b[38;5;241m=\u001b[39m arg\u001b[38;5;241m.\u001b[39mmap(cache_array)\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/tools/datetimes.py:245\u001b[0m, in \u001b[0;36m_maybe_cache\u001b[0;34m(arg, format, cache, convert_listlike)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arg, (np\u001b[38;5;241m.\u001b[39mndarray, ExtensionArray, Index, ABCSeries)):\n\u001b[1;32m    243\u001b[0m     arg \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(arg)\n\u001b[0;32m--> 245\u001b[0m unique_dates \u001b[38;5;241m=\u001b[39m \u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43marg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(unique_dates) \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mlen\u001b[39m(arg):\n\u001b[1;32m    247\u001b[0m     cache_dates \u001b[38;5;241m=\u001b[39m convert_listlike(unique_dates, \u001b[38;5;28mformat\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/algorithms.py:401\u001b[0m, in \u001b[0;36munique\u001b[0;34m(values)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munique\u001b[39m(values):\n\u001b[1;32m    308\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;124;03m    Return unique values based on a hash table.\u001b[39;00m\n\u001b[1;32m    310\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    399\u001b[0m \u001b[38;5;124;03m    array([('a', 'b'), ('b', 'a'), ('a', 'c')], dtype=object)\u001b[39;00m\n\u001b[1;32m    400\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 401\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43munique_with_mask\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/algorithms.py:440\u001b[0m, in \u001b[0;36munique_with_mask\u001b[0;34m(values, mask)\u001b[0m\n\u001b[1;32m    438\u001b[0m table \u001b[38;5;241m=\u001b[39m hashtable(\u001b[38;5;28mlen\u001b[39m(values))\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 440\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m \u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munique\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m     uniques \u001b[38;5;241m=\u001b[39m _reconstruct_data(uniques, original\u001b[38;5;241m.\u001b[39mdtype, original)\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m uniques\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "from clickhouse_driver import Client\n",
    "\n",
    "# --- Настройка ---\n",
    "# Убедитесь, что Jupyter может найти ваши модули.\n",
    "# Раскомментируйте и настройте путь, если ваш ноутбук находится не в корне проекта.\n",
    "# sys.path.append('../') \n",
    "\n",
    "try:\n",
    "    # Импортируем \"внутреннюю\" функцию, которую хотим протестировать\n",
    "    from sync_orchestrator import _monthly_bulk_load\n",
    "    from utils.types import SourceType\n",
    "    print(\"✅  Модули успешно импортированы.\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Ошибка импорта: {e}\")\n",
    "    print(\"   Убедитесь, что ноутбук запущен из корневой папки или sys.path настроен правильно.\")\n",
    "    sys.exit() # Прерываем выполнение, если импорт не удался\n",
    "\n",
    "# --- Конфигурация теста ---\n",
    "CLICKHOUSE_HOST = '172.16.0.9'\n",
    "TICKER_TO_TEST = \"BTCUSDT\"\n",
    "SOURCE_TO_TEST: SourceType = \"BINANCE-FUT\"\n",
    "\n",
    "DATA_TABLE = 'hl5s_test'\n",
    "CONTROL_TABLE = 'hl5s_daily_downloaded'\n",
    "\n",
    "# Настраиваем логирование прямо в ячейке для наглядности\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    datefmt='%Y-%m-%d %H:%M:%S',\n",
    "    stream=sys.stdout  # Выводим логи в вывод ячейки\n",
    ")\n",
    "\n",
    "\n",
    "# --- 1. Подключение к ClickHouse и очистка перед тестом ---\n",
    "client = None\n",
    "try:\n",
    "    logging.info(f\"Подключаемся к ClickHouse по адресу: {CLICKHOUSE_HOST}...\")\n",
    "    client = Client(CLICKHOUSE_HOST, settings={'use_numpy': True}, password='123' )\n",
    "    \n",
    "    logging.warning(f\"--- 1. ОЧИСТКА ПЕРЕД ТЕСТОМ ---\")\n",
    "    logging.warning(f\"Удаляем все предыдущие записи для {TICKER_TO_TEST} ({SOURCE_TO_TEST})...\")\n",
    "    \n",
    "    params = {'source': SOURCE_TO_TEST, 'ticker': TICKER_TO_TEST}\n",
    "    \n",
    "    # Очищаем основную таблицу данных\n",
    "    client.execute(f\"ALTER TABLE {DATA_TABLE} DELETE WHERE Source = %(source)s AND Ticker = %(ticker)s\", params)\n",
    "    logging.info(f\"Таблица '{DATA_TABLE}' очищена.\")\n",
    "    \n",
    "    # Очищаем контрольную таблицу\n",
    "    client.execute(f\"ALTER TABLE {CONTROL_TABLE} DELETE WHERE Source = %(source)s AND Ticker = %(ticker)s\", params)\n",
    "    logging.info(f\"Таблица '{CONTROL_TABLE}' очищена.\")\n",
    "    \n",
    "    logging.warning(\"--- Очистка завершена. Начинаем тест. ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Ошибка на этапе подготовки (подключение или очистка): {e}\")\n",
    "    # Если не удалось даже подготовиться, прерываем выполнение\n",
    "    client = None\n",
    "\n",
    "\n",
    "# --- 2. Запуск основной функции _monthly_bulk_load ---\n",
    "if client:\n",
    "    try:\n",
    "        logging.info(f\"\\n--- 2. ЗАПУСК _monthly_bulk_load для {TICKER_TO_TEST} ---\")\n",
    "        logging.info(\"Этот процесс может занять значительное время...\")\n",
    "        \n",
    "        # Вызываем функцию, которую тестируем\n",
    "        _monthly_bulk_load(\n",
    "            source=SOURCE_TO_TEST,\n",
    "            ticker=TICKER_TO_TEST,\n",
    "            client=client\n",
    "        )\n",
    "        \n",
    "        logging.info(f\"--- Тест _monthly_bulk_load для {TICKER_TO_TEST} УСПЕШНО ЗАВЕРШЕН ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"--- ТЕСТ ПРЕРВАН С ОШИБКОЙ ---\")\n",
    "        logging.critical(f\"Ошибка во время выполнения _monthly_bulk_load: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "# --- 3. Верификация результата ---\n",
    "if client:\n",
    "    try:\n",
    "        logging.info(\"\\n--- 3. ВЕРИФИКАЦИЯ РЕЗУЛЬТАТА ---\")\n",
    "        params = {'source': SOURCE_TO_TEST, 'ticker': TICKER_TO_TEST}\n",
    "\n",
    "        # Проверяем, сколько строк вставилось в основную таблицу\n",
    "        count_data = client.execute(f\"SELECT count() FROM {DATA_TABLE} WHERE Source = %(source)s AND Ticker = %(ticker)s\", params)[0][0]\n",
    "        logging.info(f\"Итого строк в '{DATA_TABLE}' для {TICKER_TO_TEST}: {count_data:,}\")\n",
    "\n",
    "        # Проверяем, сколько строк вставилось в контрольную таблицу\n",
    "        count_control = client.execute(f\"SELECT count() FROM {CONTROL_TABLE} WHERE Source = %(source)s AND Ticker = %(ticker)s\", params)[0][0]\n",
    "        logging.info(f\"Итого строк в '{CONTROL_TABLE}' для {TICKER_TO_TEST}: {count_control:,} (количество дней)\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка на этапе верификации: {e}\")\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe27edb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 05:05:44 - INFO - --- Начинаем синхронизацию для BTCUSDT (BINANCE-FUT) ---\n",
      "2025-07-27 05:05:44 - INFO - [BTCUSDT][BINANCE-FUT] Записи не найдены. Запускаем начальную массовую загрузку (monthly)...\n",
      "2025-07-27 05:05:44 - INFO - [BTCUSDT][BINANCE-FUT] Начальная загрузка: ищем месячные архивы...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 05:05:46 - INFO - [BTCUSDT][BINANCE-FUT] Найдено 70 месячных архивов в диапазоне с 2019-09 по 2025-06. Начинаем обработку...\n",
      "2025-07-27 05:05:46 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2019-09 (размер: 14.24 MB)...\n",
      "2025-07-27 05:05:46 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2019-09...\n",
      "2025-07-27 05:05:49 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2019-09 успешно скачан (14.24 MB).\n",
      "2025-07-27 05:05:49 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2019-09...\n",
      "2025-07-27 05:05:50 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:05:50 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2019-09...\n",
      "2025-07-27 05:05:50 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:05:50 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2019-09...\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2019-09 успешно обработаны.\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2019-09-08 17:57:55 по 2019-10-01 00:00:00\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 306414 баров в 'hl5s_test'...\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 23 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2019-09 успешно загружен.\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2019-10 (размер: 53.26 MB)...\n",
      "2025-07-27 05:05:52 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2019-10...\n",
      "2025-07-27 05:05:57 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2019-10 успешно скачан (53.26 MB).\n",
      "2025-07-27 05:05:57 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2019-10...\n",
      "2025-07-27 05:05:58 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:05:58 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2019-10...\n",
      "2025-07-27 05:05:58 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:05:58 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2019-10...\n",
      "2025-07-27 05:06:05 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2019-10 успешно обработаны.\n",
      "2025-07-27 05:06:05 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2019-10-01 00:00:05 по 2019-11-01 00:00:00\n",
      "2025-07-27 05:06:05 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 494018 баров в 'hl5s_test'...\n",
      "2025-07-27 05:06:06 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:06:06 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2019-10 успешно загружен.\n",
      "2025-07-27 05:06:06 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2019-11 (размер: 119.66 MB)...\n",
      "2025-07-27 05:06:06 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2019-11...\n",
      "2025-07-27 05:06:28 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2019-11 успешно скачан (119.66 MB).\n",
      "2025-07-27 05:06:28 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2019-11...\n",
      "2025-07-27 05:06:29 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:06:29 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2019-11...\n",
      "2025-07-27 05:06:30 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:06:30 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2019-11...\n",
      "2025-07-27 05:06:47 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2019-11 успешно обработаны.\n",
      "2025-07-27 05:06:47 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2019-11-01 00:00:05 по 2019-12-01 00:00:00\n",
      "2025-07-27 05:06:47 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 471378 баров в 'hl5s_test'...\n",
      "2025-07-27 05:06:48 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:06:48 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2019-11 успешно загружен.\n",
      "2025-07-27 05:06:48 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2019-12 (размер: 99.77 MB)...\n",
      "2025-07-27 05:06:48 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2019-12...\n",
      "2025-07-27 05:06:57 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2019-12 успешно скачан (99.77 MB).\n",
      "2025-07-27 05:06:57 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2019-12...\n",
      "2025-07-27 05:06:57 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:06:57 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2019-12...\n",
      "2025-07-27 05:06:58 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:06:58 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2019-12...\n",
      "2025-07-27 05:07:11 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2019-12 успешно обработаны.\n",
      "2025-07-27 05:07:11 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2019-12-01 00:00:05 по 2019-12-31 23:59:55\n",
      "2025-07-27 05:07:11 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 480338 баров в 'hl5s_test'...\n",
      "2025-07-27 05:07:12 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:07:12 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2019-12 успешно загружен.\n",
      "2025-07-27 05:07:12 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-01 (размер: 128.84 MB)...\n",
      "2025-07-27 05:07:12 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-01...\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-01 успешно скачан (128.84 MB).\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-01...\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-01...\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:07:22 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-01...\n",
      "2025-07-27 05:07:39 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-01 успешно обработаны.\n",
      "2025-07-27 05:07:40 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-01-01 00:00:05 по 2020-02-01 00:00:00\n",
      "2025-07-27 05:07:40 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 489832 баров в 'hl5s_test'...\n",
      "2025-07-27 05:07:41 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:07:41 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-01 успешно загружен.\n",
      "2025-07-27 05:07:41 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-02 (размер: 119.15 MB)...\n",
      "2025-07-27 05:07:41 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-02...\n",
      "2025-07-27 05:08:03 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-02 успешно скачан (119.15 MB).\n",
      "2025-07-27 05:08:03 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-02...\n",
      "2025-07-27 05:08:03 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:08:03 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-02...\n",
      "2025-07-27 05:08:04 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:08:04 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-02...\n",
      "2025-07-27 05:08:19 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-02 успешно обработаны.\n",
      "2025-07-27 05:08:19 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-02-01 00:00:05 по 2020-03-01 00:00:00\n",
      "2025-07-27 05:08:19 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 469261 баров в 'hl5s_test'...\n",
      "2025-07-27 05:08:21 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 29 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:08:21 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-02 успешно загружен.\n",
      "2025-07-27 05:08:21 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-03 (размер: 298.09 MB)...\n",
      "2025-07-27 05:08:21 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-03...\n",
      "2025-07-27 05:08:54 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-03 успешно скачан (298.09 MB).\n",
      "2025-07-27 05:08:54 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-03...\n",
      "2025-07-27 05:08:55 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:08:55 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-03...\n",
      "2025-07-27 05:08:56 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:08:56 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-03...\n",
      "2025-07-27 05:09:38 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-03 успешно обработаны.\n",
      "2025-07-27 05:09:38 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-03-01 00:00:05 по 2020-04-01 00:00:00\n",
      "2025-07-27 05:09:38 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 526200 баров в 'hl5s_test'...\n",
      "2025-07-27 05:09:39 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:09:39 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-03 успешно загружен.\n",
      "2025-07-27 05:09:39 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-04 (размер: 317.10 MB)...\n",
      "2025-07-27 05:09:39 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-04...\n",
      "2025-07-27 05:10:13 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-04 успешно скачан (317.10 MB).\n",
      "2025-07-27 05:10:13 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-04...\n",
      "2025-07-27 05:10:14 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:10:14 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-04...\n",
      "2025-07-27 05:10:15 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:10:15 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-04...\n",
      "2025-07-27 05:11:00 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-04 успешно обработаны.\n",
      "2025-07-27 05:11:00 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-04-01 00:00:05 по 2020-05-01 00:00:00\n",
      "2025-07-27 05:11:00 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 515323 баров в 'hl5s_test'...\n",
      "2025-07-27 05:11:02 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:11:02 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-04 успешно загружен.\n",
      "2025-07-27 05:11:02 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-05 (размер: 370.92 MB)...\n",
      "2025-07-27 05:11:02 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-05...\n",
      "2025-07-27 05:11:25 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-05 успешно скачан (370.92 MB).\n",
      "2025-07-27 05:11:25 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-05...\n",
      "2025-07-27 05:11:25 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:11:25 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-05...\n",
      "2025-07-27 05:11:26 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:11:26 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-05...\n",
      "2025-07-27 05:12:18 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-05 успешно обработаны.\n",
      "2025-07-27 05:12:18 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-05-01 00:00:10 по 2020-06-01 00:00:00\n",
      "2025-07-27 05:12:18 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 535233 баров в 'hl5s_test'...\n",
      "2025-07-27 05:12:19 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:12:19 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-05 успешно загружен.\n",
      "2025-07-27 05:12:19 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-06 (размер: 196.31 MB)...\n",
      "2025-07-27 05:12:19 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-06...\n",
      "2025-07-27 05:12:34 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-06 успешно скачан (196.31 MB).\n",
      "2025-07-27 05:12:34 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-06...\n",
      "2025-07-27 05:12:34 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:12:34 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-06...\n",
      "2025-07-27 05:12:35 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:12:35 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-06...\n",
      "2025-07-27 05:13:02 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-06 успешно обработаны.\n",
      "2025-07-27 05:13:03 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-06-01 00:00:05 по 2020-07-01 00:00:00\n",
      "2025-07-27 05:13:03 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 513912 баров в 'hl5s_test'...\n",
      "2025-07-27 05:13:04 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:13:04 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-06 успешно загружен.\n",
      "2025-07-27 05:13:04 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-07 (размер: 169.20 MB)...\n",
      "2025-07-27 05:13:04 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-07...\n",
      "2025-07-27 05:13:15 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-07 успешно скачан (169.20 MB).\n",
      "2025-07-27 05:13:15 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-07...\n",
      "2025-07-27 05:13:16 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:13:16 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-07...\n",
      "2025-07-27 05:13:17 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:13:17 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-07...\n",
      "2025-07-27 05:13:43 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-07 успешно обработаны.\n",
      "2025-07-27 05:13:43 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-07-01 00:00:05 по 2020-08-01 00:00:00\n",
      "2025-07-27 05:13:43 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 520820 баров в 'hl5s_test'...\n",
      "2025-07-27 05:13:44 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:13:44 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-07 успешно загружен.\n",
      "2025-07-27 05:13:44 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-08 (размер: 228.78 MB)...\n",
      "2025-07-27 05:13:44 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-08...\n",
      "2025-07-27 05:14:13 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-08 успешно скачан (228.78 MB).\n",
      "2025-07-27 05:14:13 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-08...\n",
      "2025-07-27 05:14:14 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:14:14 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-08...\n",
      "2025-07-27 05:14:15 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:14:15 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-08...\n",
      "2025-07-27 05:14:49 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-08 успешно обработаны.\n",
      "2025-07-27 05:14:49 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-08-01 00:00:05 по 2020-09-01 00:00:00\n",
      "2025-07-27 05:14:49 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 532124 баров в 'hl5s_test'...\n",
      "2025-07-27 05:14:50 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:14:50 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-08 успешно загружен.\n",
      "2025-07-27 05:14:50 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-09 (размер: 215.43 MB)...\n",
      "2025-07-27 05:14:50 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-09...\n",
      "2025-07-27 05:15:18 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-09 успешно скачан (215.43 MB).\n",
      "2025-07-27 05:15:18 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-09...\n",
      "2025-07-27 05:15:19 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:15:19 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-09...\n",
      "2025-07-27 05:15:19 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:15:19 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-09...\n",
      "2025-07-27 05:15:54 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-09 успешно обработаны.\n",
      "2025-07-27 05:15:54 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-09-01 00:00:05 по 2020-10-01 00:00:00\n",
      "2025-07-27 05:15:54 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 514709 баров в 'hl5s_test'...\n",
      "2025-07-27 05:15:55 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:15:55 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-09 успешно загружен.\n",
      "2025-07-27 05:15:55 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-10 (размер: 248.47 MB)...\n",
      "2025-07-27 05:15:55 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-10...\n",
      "2025-07-27 05:16:24 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-10 успешно скачан (248.47 MB).\n",
      "2025-07-27 05:16:24 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-10...\n",
      "2025-07-27 05:16:25 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:16:25 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-10...\n",
      "2025-07-27 05:16:26 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:16:26 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-10...\n",
      "2025-07-27 05:17:05 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-10 успешно обработаны.\n",
      "2025-07-27 05:17:05 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-10-01 00:00:05 по 2020-11-01 00:00:00\n",
      "2025-07-27 05:17:05 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 531607 баров в 'hl5s_test'...\n",
      "2025-07-27 05:17:06 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:17:06 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-10 успешно загружен.\n",
      "2025-07-27 05:17:06 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-11 (размер: 486.40 MB)...\n",
      "2025-07-27 05:17:06 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-11...\n",
      "2025-07-27 05:17:37 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-11 успешно скачан (486.40 MB).\n",
      "2025-07-27 05:17:37 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-11...\n",
      "2025-07-27 05:17:37 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:17:37 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-11...\n",
      "2025-07-27 05:17:39 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:17:39 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-11...\n",
      "2025-07-27 05:18:52 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-11 успешно обработаны.\n",
      "2025-07-27 05:18:52 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-11-01 00:00:05 по 2020-12-01 00:00:00\n",
      "2025-07-27 05:18:52 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 518222 баров в 'hl5s_test'...\n",
      "2025-07-27 05:18:53 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 30 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:18:53 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-11 успешно загружен.\n",
      "2025-07-27 05:18:53 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2020-12 (размер: 549.43 MB)...\n",
      "2025-07-27 05:18:53 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2020-12...\n",
      "2025-07-27 05:19:40 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2020-12 успешно скачан (549.43 MB).\n",
      "2025-07-27 05:19:40 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2020-12...\n",
      "2025-07-27 05:19:40 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:19:40 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2020-12...\n",
      "2025-07-27 05:19:42 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:19:42 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2020-12...\n",
      "2025-07-27 05:21:02 - INFO - [BTCUSDT][BINANCE-FUT] Данные из файла за 2020-12 успешно обработаны.\n",
      "2025-07-27 05:21:02 - INFO - [BTCUSDT][BINANCE-FUT] Диапазон времени для вставки: с 2020-12-01 00:00:05 по 2021-01-01 00:00:00\n",
      "2025-07-27 05:21:02 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 535516 баров в 'hl5s_test'...\n",
      "2025-07-27 05:21:03 - INFO - [BTCUSDT][BINANCE-FUT] Вставляем 31 записей в 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:21:03 - INFO - [BTCUSDT][BINANCE-FUT] Месяц 2020-12 успешно загружен.\n",
      "2025-07-27 05:21:03 - INFO - [BTCUSDT][BINANCE-FUT] Обрабатываем месяц 2021-01 (размер: 1054.50 MB)...\n",
      "2025-07-27 05:21:03 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание основного файла за 2021-01...\n",
      "2025-07-27 05:22:08 - INFO - [BTCUSDT][BINANCE-FUT] Основной файл за 2021-01 успешно скачан (1054.50 MB).\n",
      "2025-07-27 05:22:08 - INFO - [BTCUSDT][BINANCE-FUT] Скачивание файла контрольной суммы за 2021-01...\n",
      "2025-07-27 05:22:09 - INFO - [BTCUSDT][BINANCE-FUT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 05:22:09 - INFO - [BTCUSDT][BINANCE-FUT] Начало проверки SHA-256 для файла за 2021-01...\n",
      "2025-07-27 05:22:12 - INFO - [BTCUSDT][BINANCE-FUT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 05:22:12 - INFO - [BTCUSDT][BINANCE-FUT] Начало обработки данных из файла за 2021-01...\n",
      "2025-07-27 05:23:32 - ERROR - [BTCUSDT][BINANCE-FUT] Ошибка при обработке месяца 2021-01: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "2025-07-27 05:23:32 - WARNING - [BTCUSDT][BINANCE-FUT] Сбой операции. Запускаем очистку данных за 2021-01...\n",
      "2025-07-27 05:23:32 - INFO - [BTCUSDT][BINANCE-FUT] Очистка 'hl5s_test'...\n",
      "2025-07-27 05:23:32 - INFO - [BTCUSDT][BINANCE-FUT] Очистка 'hl5s_daily_downloaded'...\n",
      "2025-07-27 05:23:32 - WARNING - [BTCUSDT][BINANCE-FUT] Очистка данных за 2021-01 успешно завершена.\n",
      "2025-07-27 05:23:32 - CRITICAL - Критическая ошибка при синхронизации BTCUSDT: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py\", line 175, in sync_ticker_data\n",
      "    _monthly_bulk_load(source, ticker, data_table, control_table, client)\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py\", line 99, in _monthly_bulk_load\n",
      "    raise e\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py\", line 63, in _monthly_bulk_load\n",
      "    full_df = download_and_process_ticks_to_df(trade_date=month_date, ticker=ticker, source=source, frequency=\"monthly\")\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/decorators.py\", line 42, in wrapper\n",
      "    # Если это не последняя попытка, логируем предупреждение и ждем\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py\", line 130, in download_and_process_ticks_to_df\n",
      "    raise e\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py\", line 119, in download_and_process_ticks_to_df\n",
      "    processed_chunks = _process_chunk_iterator(chunk_iterator, progress_callback)\n",
      "  File \"/home/clouduser/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py\", line 43, in _process_chunk_iterator\n",
      "    for chunk_df in chunk_iterator:\n",
      "  File \"/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1843, in __next__\n",
      "    return self.get_chunk()\n",
      "  File \"/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1985, in get_chunk\n",
      "    return self.read(nrows=size)\n",
      "  File \"/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py\", line 1923, in read\n",
      "    ) = self._engine.read(  # type: ignore[attr-defined]\n",
      "  File \"/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/c_parser_wrapper.py\", line 234, in read\n",
      "    chunks = self._reader.read_low_memory(nrows)\n",
      "  File \"parsers.pyx\", line 850, in pandas._libs.parsers.TextReader.read_low_memory\n",
      "  File \"parsers.pyx\", line 905, in pandas._libs.parsers.TextReader._read_rows\n",
      "  File \"parsers.pyx\", line 874, in pandas._libs.parsers.TextReader._tokenize_rows\n",
      "  File \"parsers.pyx\", line 891, in pandas._libs.parsers.TextReader._check_tokenize_status\n",
      "  File \"parsers.pyx\", line 2061, in pandas._libs.parsers.raise_parser_error\n",
      "pandas.errors.ParserError: Error tokenizing data. C error: Calling read(nbytes) on source failed. Try engine='python'.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258ec584",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 04:18:31 - INFO - Подключаемся к ClickHouse по адресу: 172.16.0.9...\n",
      "2025-07-27 04:18:31 - WARNING - --- Начинаем тест инкрементальной загрузки. ---\n",
      "2025-07-27 04:18:31 - INFO - \n",
      "--- 2. ЗАПУСК _daily_incremental_sync для BTCUSDT ---\n",
      "2025-07-27 04:18:31 - INFO - [BTCUSDT] Инкрементальное обновление: ищем доступные дневные файлы...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅  Модули успешно импортированы.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-27 04:18:41 - INFO - [BTCUSDT] Требуется скачать 1647 новых дневных файлов...\n",
      "2025-07-27 04:18:41 - INFO - [BTCUSDT] Обрабатываем день 2021-01-21...\n",
      "2025-07-27 04:18:41 - INFO - [BTCUSDT] Скачивание основного файла за 2021-01-21...\n",
      "2025-07-27 04:18:46 - INFO - [BTCUSDT] Основной файл за 2021-01-21 успешно скачан (47.39 MB).\n",
      "2025-07-27 04:18:46 - INFO - [BTCUSDT] Скачивание файла контрольной суммы за 2021-01-21...\n",
      "2025-07-27 04:18:47 - INFO - [BTCUSDT] Файл контрольной суммы успешно скачан.\n",
      "2025-07-27 04:18:47 - INFO - [BTCUSDT] Начало проверки SHA-256 для файла за 2021-01-21...\n",
      "2025-07-27 04:18:47 - INFO - [BTCUSDT] Контрольная сумма совпала. Данные целостны.\n",
      "2025-07-27 04:18:47 - INFO - [BTCUSDT] Начало обработки данных из файла за 2021-01-21...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 51\u001b[0m\n\u001b[1;32m     48\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- 2. ЗАПУСК _daily_incremental_sync для \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTICKER_TO_TEST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# Вызываем функцию, которую тестируем\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m     \u001b[43m_daily_incremental_sync\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSOURCE_TO_TEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mTICKER_TO_TEST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclient\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m     logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m--- Тест _daily_incremental_sync для \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTICKER_TO_TEST\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m УСПЕШНО ЗАВЕРШЕН ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py:114\u001b[0m, in \u001b[0;36m_daily_incremental_sync\u001b[0;34m(source, ticker, client)\u001b[0m\n\u001b[1;32m    112\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Обрабатываем день \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 114\u001b[0m     full_df \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_and_process_ticks_to_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrade_date\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrade_date\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdaily\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m full_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    117\u001b[0m         logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] DataFrame за \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m пуст. Записываем \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпустую\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m запись.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/decorators.py:42\u001b[0m, in \u001b[0;36mretry_on_io_error.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     41\u001b[0m         \u001b[38;5;66;03m# Попытка выполнить функцию\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IO_EXCEPTIONS \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     44\u001b[0m         last_exception \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py:120\u001b[0m, in \u001b[0;36mdownload_and_process_ticks_to_df\u001b[0;34m(trade_date, ticker, source, frequency, chunksize, progress_callback)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    116\u001b[0m     chunk_iterator \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\n\u001b[1;32m    117\u001b[0m         csv_stream, header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, names\u001b[38;5;241m=\u001b[39mfull_col_names,\n\u001b[1;32m    118\u001b[0m         usecols\u001b[38;5;241m=\u001b[39mCOLS_TO_USE, dtype\u001b[38;5;241m=\u001b[39mDTYPES, chunksize\u001b[38;5;241m=\u001b[39mchunksize\n\u001b[1;32m    119\u001b[0m     )\n\u001b[0;32m--> 120\u001b[0m     processed_chunks \u001b[38;5;241m=\u001b[39m \u001b[43m_process_chunk_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_iterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprogress_callback\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    123\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert string to float\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(e):\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py:43\u001b[0m, in \u001b[0;36m_process_chunk_iterator\u001b[0;34m(chunk_iterator, progress_callback)\u001b[0m\n\u001b[1;32m     41\u001b[0m processed_chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     42\u001b[0m total_rows_processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m---> 43\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk_df \u001b[38;5;129;01min\u001b[39;00m chunk_iterator:\n\u001b[1;32m     44\u001b[0m     total_rows_processed \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(chunk_df)\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m progress_callback:\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1843\u001b[0m, in \u001b[0;36mTextFileReader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m   1842\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1843\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_chunk\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1844\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose()\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1985\u001b[0m, in \u001b[0;36mTextFileReader.get_chunk\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m   1983\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m   1984\u001b[0m     size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmin\u001b[39m(size, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnrows \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow)\n\u001b[0;32m-> 1985\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/io/parsers/readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[0;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mDataFrame\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnew_col_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[1;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[0;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[1;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[1;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[1;32m    774\u001b[0m     )\n\u001b[1;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[1;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[0;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[43mdict_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmanager\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[1;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/internals/construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[0;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[1;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[1;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[0;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marrays_to_mgr\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtyp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtyp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/internals/construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[0;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[1;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcreate_block_manager_from_column_arrays\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[43m        \u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrefs\u001b[49m\n\u001b[1;32m    154\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/internals/managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[0;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[1;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[1;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[1;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[1;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[1;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m \u001b[43m_form_blocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43marrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconsolidate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrefs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/internals/managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[0;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[1;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[1;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[0;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m \u001b[43m_stack_arrays\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtup_block\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[1;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/pandas/core/internals/managers.py:2254\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[0;34m(tuples, dtype)\u001b[0m\n\u001b[1;32m   2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[1;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m-> 2254\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n\u001b[1;32m   2256\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m stacked, placement\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import sys\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "from clickhouse_driver import Client\n",
    "\n",
    "# --- Настройка ---\n",
    "try:\n",
    "    # Импортируем \"внутреннюю\" функцию, которую хотим протестировать\n",
    "    from sync_orchestrator import _daily_incremental_sync\n",
    "    from utils.types import SourceType\n",
    "    print(\"✅  Модули успешно импортированы.\")\n",
    "except ImportError as e:\n",
    "    print(f\"❌ Ошибка импорта: {e}\")\n",
    "    sys.exit()\n",
    "\n",
    "# --- Конфигурация теста ---\n",
    "\n",
    "\n",
    "\n",
    "DATA_TABLE = 'hl5s_test'\n",
    "CONTROL_TABLE = 'hl5s_daily_downloaded'\n",
    "\n",
    "# Настраиваем логирование\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', stream=sys.stdout)\n",
    "\n",
    "\n",
    "# --- 1. Подключение к ClickHouse и подготовка данных ---\n",
    "client = None\n",
    "try:\n",
    "    logging.info(f\"Подключаемся к ClickHouse по адресу: {CLICKHOUSE_HOST}...\")\n",
    "    client = Client(CLICKHOUSE_HOST, settings={'use_numpy': True}, password = '123')\n",
    "    \n",
    "    \n",
    "    logging.warning(\"--- Начинаем тест инкрементальной загрузки. ---\")\n",
    "\n",
    "except Exception as e:\n",
    "    logging.critical(f\"Ошибка на этапе подготовки: {e}\")\n",
    "    client = None\n",
    "\n",
    "\n",
    "# --- 2. Запуск основной функции _daily_incremental_sync ---\n",
    "if client:\n",
    "    try:\n",
    "        logging.info(f\"\\n--- 2. ЗАПУСК _daily_incremental_sync для {TICKER_TO_TEST} ---\")\n",
    "        \n",
    "        # Вызываем функцию, которую тестируем\n",
    "        _daily_incremental_sync(\n",
    "            source=SOURCE_TO_TEST,\n",
    "            ticker=TICKER_TO_TEST,\n",
    "            client=client\n",
    "        )\n",
    "        \n",
    "        logging.info(f\"--- Тест _daily_incremental_sync для {TICKER_TO_TEST} УСПЕШНО ЗАВЕРШЕН ---\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.critical(f\"--- ТЕСТ ПРЕРВАН С ОШИБКОЙ ---\")\n",
    "        logging.critical(f\"Ошибка во время выполнения _daily_incremental_sync: {e}\", exc_info=True)\n",
    "\n",
    "\n",
    "# --- 3. Верификация результата ---\n",
    "if client:\n",
    "    try:\n",
    "        logging.info(\"\\n--- 3. ВЕРИФИКАЦИЯ РЕЗУЛЬТАТА ---\")\n",
    "        params = {'source': SOURCE_TO_TEST, 'ticker': TICKER_TO_TEST, 'dates': dates_to_remove}\n",
    "\n",
    "        # Проверяем, что записи для \"удаленных\" дат снова появились в контрольной таблице\n",
    "        count_control = client.execute(f\"SELECT count() FROM {CONTROL_TABLE} WHERE Source = %(source)s AND Ticker = %(ticker)s AND Date IN %(dates)s\", params)[0][0]\n",
    "        \n",
    "        if count_control == DAYS_TO_REMOVE:\n",
    "             logging.info(f\"✅  Проверка пройдена: В '{CONTROL_TABLE}' снова появились {count_control} записи за недостающие дни.\")\n",
    "        else:\n",
    "             logging.error(f\"❌  ПРОВЕРКА НЕ ПРОЙДЕНА: Ожидалось {DAYS_TO_REMOVE} записей, а найдено {count_control}.\")\n",
    "\n",
    "        # Проверяем, что данные для \"удаленных\" дат снова появились в основной таблице\n",
    "        count_data = client.execute(f\"SELECT count() FROM {DATA_TABLE} WHERE Source = %(source)s AND Ticker = %(ticker)s AND toDate(Timestamp) IN %(dates)s\", params)[0][0]\n",
    "        \n",
    "        if count_data > 0:\n",
    "            logging.info(f\"✅  Проверка пройдена: В '{DATA_TABLE}' появились данные за недостающие дни ({count_data:,} строк).\")\n",
    "        else:\n",
    "            logging.error(f\"❌  ПРОВЕРКА НЕ ПРОЙДЕНА: Данные в '{DATA_TABLE}' за недостающие дни не были вставлены.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Ошибка на этапе верификации: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64a02699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from clickhouse_driver import Client\n",
    "CLICKHOUSE_HOST = '172.16.0.9'\n",
    "client = Client(CLICKHOUSE_HOST, settings={'use_numpy': True}, password = '123')\n",
    "\n",
    "DATA_TABLE = 'hl5s_test'\n",
    "CONTROL_TABLE = 'hl5s_daily_downloaded'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a0d193c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "client.execute(f'TRUNCATE TABLE {DATA_TABLE}')\n",
    "client.execute(f'TRUNCATE TABLE {CONTROL_TABLE}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cab6d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 25/561 [6:13:27<133:27:02, 896.31s/it] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     20\u001b[0m daily_tickers \u001b[38;5;241m=\u001b[39m get_available_tickers(\n\u001b[1;32m     21\u001b[0m     source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m     22\u001b[0m         frequency\u001b[38;5;241m=\u001b[39mfrequency_daily,\n\u001b[1;32m     23\u001b[0m         ticker_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m ticker: ticker\u001b[38;5;241m.\u001b[39mendswith( (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSDT\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mUSDC\u001b[39m\u001b[38;5;124m'\u001b[39m) ),\n\u001b[1;32m     24\u001b[0m         progress_callback\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     25\u001b[0m     )\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ticker \u001b[38;5;129;01min\u001b[39;00m tqdm(daily_tickers):\n\u001b[0;32m---> 28\u001b[0m     \u001b[43msync_ticker_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mticker\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_TABLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mCONTROL_TABLE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclient\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py:172\u001b[0m, in \u001b[0;36msync_ticker_data\u001b[0;34m(source, ticker, data_table, control_table, client)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m full_df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m    171\u001b[0m     logging\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mprefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m DataFrame за \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrade_date\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m пуст. Записываем \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mпустую\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m запись.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 172\u001b[0m     summary_record \u001b[38;5;241m=\u001b[39m create_summary_record(\n\u001b[1;32m    173\u001b[0m         trade_date\u001b[38;5;241m=\u001b[39mtrade_date,\n\u001b[1;32m    174\u001b[0m         source\u001b[38;5;241m=\u001b[39msource,\n\u001b[1;32m    175\u001b[0m         ticker\u001b[38;5;241m=\u001b[39mticker,\n\u001b[1;32m    176\u001b[0m         ticks\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    177\u001b[0m         volume\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    178\u001b[0m         )\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    180\u001b[0m     df_for_data_table \u001b[38;5;241m=\u001b[39m full_df[DATA_TABLE_COLUMNS]\u001b[38;5;241m.\u001b[39mastype(DATA_TABLE_DTYPES)\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/sync_orchestrator.py:60\u001b[0m, in \u001b[0;36m_monthly_bulk_load\u001b[0;34m(source, ticker, data_table, control_table, client)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_summary_record\u001b[39m(\n\u001b[1;32m     46\u001b[0m     trade_date: datetime\u001b[38;5;241m.\u001b[39mdate,\n\u001b[1;32m     47\u001b[0m     source: SourceType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     50\u001b[0m     volume: \u001b[38;5;28mfloat\u001b[39m\n\u001b[1;32m     51\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Dict[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m     52\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m    Создает и валидирует словарь для вставки в контрольную таблицу.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m    Сигнатура функции является формой валидации.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     record \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     57\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m: trade_date,\n\u001b[1;32m     58\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSource\u001b[39m\u001b[38;5;124m'\u001b[39m: source,\n\u001b[1;32m     59\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicker\u001b[39m\u001b[38;5;124m'\u001b[39m: ticker,\n\u001b[0;32m---> 60\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTicks\u001b[39m\u001b[38;5;124m'\u001b[39m: ticks,\n\u001b[1;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mV\u001b[39m\u001b[38;5;124m'\u001b[39m: volume\n\u001b[1;32m     62\u001b[0m     }\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;66;03m# быструю проверку на всякий случай,\u001b[39;00m\n\u001b[1;32m     65\u001b[0m     \u001b[38;5;66;03m# если CONTROL_TABLE_COLUMNS изменится, а эта функция - нет.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mset\u001b[39m(record\u001b[38;5;241m.\u001b[39mkeys()) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mset\u001b[39m(CONTROL_TABLE_COLUMNS):\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/decorators.py:39\u001b[0m, in \u001b[0;36mretry_on_io_error.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m attempt \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(retries):\n\u001b[1;32m     38\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 39\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     40\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m IO_EXCEPTIONS \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     41\u001b[0m         last_exception \u001b[38;5;241m=\u001b[39m e\n",
      "File \u001b[0;32m~/PROJECT_JUPITER/NBs/HFTMetrics/binancedownloader/utils/downloader.py:88\u001b[0m, in \u001b[0;36mdownload_and_process_ticks_to_df\u001b[0;34m(trade_date, ticker, source, frequency, chunksize, progress_callback)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;66;03m# ... (логика скачивания и проверки чексуммы без изменений) ...\u001b[39;00m\n\u001b[1;32m     87\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mticker\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m][\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msource\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] Скачивание основного файла за \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdate_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 88\u001b[0m response_zip \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m600\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     89\u001b[0m response_zip\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[1;32m     90\u001b[0m zip_content \u001b[38;5;241m=\u001b[39m response_zip\u001b[38;5;241m.\u001b[39mcontent\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/sessions.py:746\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    743\u001b[0m         \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    745\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n\u001b[0;32m--> 746\u001b[0m     \u001b[43mr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontent\u001b[49m\n\u001b[1;32m    748\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/models.py:902\u001b[0m, in \u001b[0;36mResponse.content\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    900\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    901\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 902\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCONTENT_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    904\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_content_consumed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    905\u001b[0m \u001b[38;5;66;03m# don't need to release the connection; that's been handled by urllib3\u001b[39;00m\n\u001b[1;32m    906\u001b[0m \u001b[38;5;66;03m# since we exhausted the data.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/requests/models.py:820\u001b[0m, in \u001b[0;36mResponse.iter_content.<locals>.generate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    818\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    819\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 820\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw\u001b[38;5;241m.\u001b[39mstream(chunk_size, decode_content\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    821\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    822\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m ChunkedEncodingError(e)\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/urllib3/response.py:1060\u001b[0m, in \u001b[0;36mHTTPResponse.stream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 1060\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m data:\n\u001b[1;32m   1063\u001b[0m             \u001b[38;5;28;01myield\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/urllib3/response.py:980\u001b[0m, in \u001b[0;36mHTTPResponse.read\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    978\u001b[0m         decoded_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decode(data, decode_content, flush_decoder)\n\u001b[1;32m    979\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_decoded_buffer\u001b[38;5;241m.\u001b[39mput(decoded_data)\n\u001b[0;32m--> 980\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_decoded_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    982\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/urllib3/response.py:264\u001b[0m, in \u001b[0;36mBytesQueueBuffer.get\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn should be > 0\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    263\u001b[0m fetched \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m--> 264\u001b[0m ret \u001b[38;5;241m=\u001b[39m \u001b[43mio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBytesIO\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m fetched \u001b[38;5;241m<\u001b[39m n:\n\u001b[1;32m    266\u001b[0m     remaining \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m-\u001b[39m fetched\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#ONE-THREAD!\n",
    "SOURCE_TO_SYNC='BINANCE-FUT'\n",
    "from utils.discovery import get_available_tickers, SourceType, Frequency\n",
    "\n",
    "from sync_orchestrator import sync_ticker_data\n",
    "from utils.types import SourceType\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Настраиваем логирование\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', \n",
    "                    #stream=sys.stdout,\n",
    "                    filename='./sync_process.log',\n",
    "                    filemode='a'\n",
    ")\n",
    "\n",
    "daily_tickers = get_available_tickers(\n",
    "    source=SOURCE_TO_SYNC,\n",
    "        frequency=\"daily\",\n",
    "        ticker_filter=lambda ticker: ticker.endswith( ('USDT','USDC') ),\n",
    "        progress_callback=None\n",
    "    )\n",
    "\n",
    "for ticker in tqdm(daily_tickers):\n",
    "    sync_ticker_data(SOURCE_TO_SYNC, ticker, DATA_TABLE, CONTROL_TABLE, client)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b8615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Найдено 561 тикеров. Запускаем параллельную обработку на 3 процессах...\n",
      "Режим 'Dry Run': True\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "26b698712f3a40d7abfa3ef885c0a5f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/561 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Process ForkPoolWorker-6:\n",
      "Process ForkPoolWorker-5:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/multiprocessing/pool.py:856\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    855\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 856\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_items\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    857\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mIndexError\u001b[39;00m:\n",
      "\u001b[0;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 45\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mРежим \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDry Run\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDRY_RUN_MODE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Pool(processes\u001b[38;5;241m=\u001b[39mNUM_PROCESSES) \u001b[38;5;28;01mas\u001b[39;00m pool:\n\u001b[0;32m---> 45\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimap_unordered\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_sync_in_process\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Обработка завершена. Итоги: ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     50\u001b[0m success_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m results \u001b[38;5;28;01mif\u001b[39;00m r[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mstatus\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOK\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/tqdm/notebook.py:250\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    249\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[0;32m--> 250\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[1;32m    251\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[1;32m    252\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m    253\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1182\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1183\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1184\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/multiprocessing/pool.py:861\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    859\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    860\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 861\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cond\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    862\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    863\u001b[0m     item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_items\u001b[38;5;241m.\u001b[39mpopleft()\n",
      "File \u001b[0;32m/opt/conda/envs/PYTHON310/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#MULTI-THREAD\n",
    "import os\n",
    "from multiprocessing import Pool\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "from utils.discovery import get_available_tickers\n",
    "from sync_orchestrator import run_sync_in_process, ENV_CH_HOST, ENV_CH_PASSWORD, ENV_LOG_LEVEL\n",
    "\n",
    "\n",
    "SOURCE_TO_SYNC='BINANCE-FUT'\n",
    "DATA_TABLE_NAME = 'hl5s_test'\n",
    "CONTROL_TABLE_NAME = 'hl5s_daily_downloaded'\n",
    "NUM_PROCESSES = 3\n",
    "DRY_RUN_MODE = True\n",
    "\n",
    "LOG_LEVEL = 'INFO'\n",
    "CLICKHOUSE_HOST = '172.16.0.9'\n",
    "CLICKHOUSE_PASSWORD = '123'\n",
    "\n",
    "os.environ[ENV_CH_HOST] = CLICKHOUSE_HOST\n",
    "os.environ[ENV_LOG_LEVEL] = LOG_LEVEL\n",
    "os.environ[ENV_CH_PASSWORD] = CLICKHOUSE_PASSWORD\n",
    "\n",
    "ticker_filter = lambda ticker: ticker.endswith( ('USDT','USDC') )\n",
    "\n",
    "tickers = get_available_tickers(\n",
    "    source=SOURCE_TO_SYNC,\n",
    "        frequency=\"daily\",\n",
    "        ticker_filter = ticker_filter,\n",
    "        progress_callback=None\n",
    "    )\n",
    "params = {\n",
    "    \"source\": SOURCE_TO_SYNC,\n",
    "    \"data_table\": DATA_TABLE_NAME,\n",
    "    \"control_table\": CONTROL_TABLE_NAME,\n",
    "    \"dry_run\": DRY_RUN_MODE\n",
    "}\n",
    "\n",
    "tasks = [  {**params, \"ticker\": _}  for _ in tickers ]\n",
    "print(f\"Найдено {len(tasks)} тикеров. Запускаем параллельную обработку на {NUM_PROCESSES} процессах...\")\n",
    "print(f\"Режим 'Dry Run': {DRY_RUN_MODE}\")\n",
    "\n",
    "with Pool(processes=NUM_PROCESSES) as pool:\n",
    "    results = list(\n",
    "        tqdm(pool.imap_unordered(run_sync_in_process, tasks), total=len(tasks))\n",
    "    )\n",
    "\n",
    "print(\"\\n--- Обработка завершена. Итоги: ---\")\n",
    "success_count = sum(1 for r in results if r['status'] == \"OK\")\n",
    "fail_count = len(results) - success_count\n",
    "print(f\"Успешно: {success_count}, С ошибками: {fail_count}\")\n",
    "\n",
    "if fail_count > 0:\n",
    "    print(\"\\nТикеры с ошибками:\")\n",
    "    for res in results:\n",
    "        if res['status'] == \"FAILED\":\n",
    "            print(f\" - {res['ticker']}: {res['error']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (PYTHON310)",
   "language": "python",
   "name": "python310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
